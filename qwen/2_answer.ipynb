{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1603061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# cuBLAS 결정적 모드 (둘 중 하나 사용) — 반드시 torch import 전에 설정\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"   # 더 큰 워크스페이스\n",
    "\n",
    "# (선택) 기타 재현성 관련\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "import random, numpy as np, torch\n",
    "\n",
    "# 완전 결정적 모드\n",
    "torch.use_deterministic_algorithms(True, warn_only=False)\n",
    "\n",
    "# cuDNN/TF32 설정\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "# 시드 고정\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "import argparse, io, base64, re, requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "\n",
    "SYSTEM_RULES = (\n",
    "    \"You are a multimodal assistant.\\n\"\n",
    "    \"\\n\"\n",
    "    \"GLOBAL FORMAT RULES:\\n\"\n",
    "    \"- Output exactly ONE final block with NO role tags, headers, lists, or extra sections.\\n\"\n",
    "    \"- Never enumerate (no (i)/(ii), numbers, bullets). Do NOT echo instructions.\\n\"\n",
    "    \"- Do NOT wrap output in quotes. No leading/trailing spaces or trailing newline.\\n\"\n",
    "    \"- Preserve original casing, punctuation, and spacing from the source when answering spans.\\n\"\n",
    "    \"\\n\"\n",
    "    \"TASK STYLES (use [TASK_HINT] when present; otherwise infer from inputs):\\n\"\n",
    "    \"1) captioning (image, no explicit question):\\n\"\n",
    "    \"   - Begin the caption with: 'The image is ...'\\n\"\n",
    "    \"   - Write a detailed description in 2–6 sentences (paragraph style), no labels.\\n\"\n",
    "    \"   - No quotes. No list formatting.\\n\"\n",
    "    \"\\n\"\n",
    "    \"2) vqa (image + question):\\n\"\n",
    "    \"   - Return ONLY the exact short answer span as plain text (one line).\\n\"\n",
    "    \"   - Do NOT add words, punctuation, or explanations. Do NOT normalize case or numbers.\\n\"\n",
    "    \"\\n\"\n",
    "    \"3) math_reasoning (word problems):\\n\"\n",
    "    \"   - You MUST output step-by-step reasoning FIRST, then a blank line, then the final line.\\n\"\n",
    "    \"   - Use the numbers from the problem in the steps. Keep units only if required by the answer.\\n\"\n",
    "    \"   - Do NOT output the final line until after the steps are written.\\n\"\n",
    "    \"   - Write ONLY 4–8 SHORT plain sentences, NO bullets/numbers/latex. NO introductions like 'To determine...' and NO variables such as x.\\n\"\n",
    "    \"   - Each sentence MUST include at least one inline computation marker like '<<a+b=c>>', '<<a-b=c>>', '<<a*b=c>>', or '<<a/b=c>>'. Use the given numbers directly.\\n\"\n",
    "    \"   - Keep the style compact as in the dataset examples.\\n\"\n",
    "    \"   - After the sentences, add ONE blank line and then the final line EXACTLY: '#### <final_answer>' (digits only; decimal allowed; no commas/units).\\n\"\n",
    "    \"   - Examples:\\n\"\n",
    "    \"     Dad gave Olaf 10 toy cars, Mom gave 10 + 5 = <<10+5=15>>15. Auntie gave 6, Uncle gave 6 - 1 = <<6-1=5>>5, Grandpa gave 2 * 5 = <<2*5=10>>10. All gifts total 10 + 15 + 6 + 5 + 10 = <<10+15+6+5+10=46>>46. Olaf now has 150 + 46 = <<150+46=196>>196.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 196\\n\"\n",
    "    \"     He has 6 - 2 = <<6-2=4>>4 cats. He has 4 - 1 = <<4-1=3>>3 parrots. He has 4 + 6 = <<4+6=10>>10 snakes. Total pets 2 + 4 + 3 + 10 = <<2+4+3+10=19>>19.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 19\\n\"\n",
    "    \"     She spend $56 because 7 * 8 = <<7*8=56>>56. She has 100 - 56 = <<100-56=44>>44 left. She can get 44 / 5 = <<44/5=8.8>>8.8 five-dollar bills → $40 because 8 * 5 = <<8*5=40>>40. Money left 44 - 40 = <<44-40=4>>4.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 4\\n\"\n",
    "    \"     Mimi picked up 2 dozen seashells, which is <<2*12=24>> shells. Kyle found twice as many, so <<24*2=48>> shells. Leigh grabbed one-third of Kyle's shells, so <<48/3=16>> shells.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 16\\n\"\n",
    "    \"\\n\"\n",
    "    \"4) summarization (long text, no direct question):\\n\"\n",
    "    \"   - If a formal act title exists (e.g., explicit short title line or '<TITLE> of <YEAR>'), OUTPUT EXACTLY '<TITLE> - <summary>' on ONE line.\\n\"\n",
    "    \"   - The part AFTER ' - ' MUST be a NON-EMPTY summary of 20–60 words (1–3 sentences). Title-only output is INVALID.\\n\"\n",
    "    \"   - If no clear title exists, output a single-line summary of 20–60 words (no line breaks).\\n\"\n",
    "    \"   - NEVER include raw headings like 'SECTION 1. SHORT TITLE.' or 'SEC.' in the output. Do NOT write 'Title - ...'. Start with the actual title text only.\\n\"\n",
    "    \"   - Do NOT mention 'image' or 'document'. Focus on the bill’s purpose, actions (Directs/Requires/Establishes/Authorizes), scope, and any key targets/timelines.\\n\"\n",
    "    \"   - If your draft lacks the ' - ' or has fewer than 20 words after it, treat it as INVALID and rewrite before finishing.\\n\"\n",
    "    \"   - Examples:\\n\"\n",
    "    \"     'Veterans Access to Timely Medical Appointments Act - Directs VA to implement a standardized scheduling policy with 7-day primary care and 14-day specialty targets, require reliable wait-time data, strengthen training and oversight, improve phone access, and publish performance reports.'\\n\"\n",
    "    \"     'King Holiday and Service Act of 1994 - Extends and revises the commission honoring Martin Luther King, Jr., expands service opportunities and grant authority, updates reporting and membership requirements, and aligns provisions in the National and Community Service Act.'\\n\"\n",
    "    \"     'Establishes the Commission To Assess the Nuclear Activities of the Islamic Republic of Iran which shall assess the status of, the relationship between, and the intentions behind the military and the civilian nuclear activities of the Islamic Republic of Iran.\\n\\nTerminates the Commission 60 days after submission of the report required under this Act.'\\n\"\n",
    "    \"\\n\"\n",
    "    \"5) text_qa (multiple questions provided):\\n\"\n",
    "    \"   - Return a Python-style dict string with ONLY one key: 'input_text'.\\n\"\n",
    "    \"   - Its value is a JSON-like list of answers in the SAME order as the questions.\\n\"\n",
    "    \"   - Example: {'input_text': ['ans1', 'ans2', 'ans3']}\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_prompt(row: dict) -> str:\n",
    "    lines = []\n",
    "    if row.get(\"task\"):     lines.append(f\"[TASK_HINT]: {row['task']}\")\n",
    "    if row.get(\"question\"): lines.append(f\"[QUESTION]: {row['question']}\")\n",
    "    if row.get(\"input_type\") == \"text\" and row.get(\"input\"):\n",
    "        lines.append(f\"[TEXT]: {row['input']}\")\n",
    "    lines.append(\"Respond with the single best answer only.\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# <<< CHANGED: messages엔 '자리표시자'만 두고, PIL 이미지는 넣지 않음\n",
    "def build_messages(row, has_image: bool):\n",
    "    user_content = []\n",
    "    if has_image:\n",
    "        user_content.append({\"type\": \"image\"})  # 자리표시자만\n",
    "    user_content.append({\"type\": \"text\", \"text\": build_prompt(row)})\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\":\"text\", \"text\": SYSTEM_RULES}]},\n",
    "        {\"role\": \"user\",   \"content\": user_content},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def load_image_any(x: str):\n",
    "    if not isinstance(x, str):\n",
    "        return None\n",
    "    if x.startswith(\"http://\") or x.startswith(\"https://\"):\n",
    "        try:\n",
    "            r = requests.get(x, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            return None\n",
    "    try:\n",
    "        raw = base64.b64decode(x, validate=True)\n",
    "        return Image.open(io.BytesIO(raw)).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def find_id_col(df: pd.DataFrame):\n",
    "    for c in (\"ID\",\"id\"):\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\":\"ID\"}, inplace=True)\n",
    "    return \"ID\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2214: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:32<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: Qwen/Qwen2.5-VL-7B-Instruct on cuda:0\n",
      "Data loaded: ../data/deep_chal_multitask_dataset_test.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2493/2493 [7:12:16<00:00, 10.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: finetune_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "data_path = '../data/deep_chal_multitask_dataset_test.parquet'\n",
    "out_path = \"finetune_submission.csv\"\n",
    "\n",
    "#6560\n",
    "LoRA_DIR = \"./qwen2_5_vl_7b_lora_2\"\n",
    "\n",
    "# 4bit 로드(메모리 절약).\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "device_map = \"auto\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "base = AutoModelForVision2Seq.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, os.path.join(LoRA_DIR, \"lora_adapter\"))\n",
    "model.eval()\n",
    "print(f\"Loaded model: {MODEL_NAME} on {model.device}\")\n",
    "\n",
    "\n",
    "df = pd.read_parquet(data_path, engine='fastparquet')\n",
    "id_col = find_id_col(df)\n",
    "print('Data loaded:', data_path)\n",
    "\n",
    "\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=352,\n",
    "    temperature=0.1,\n",
    "    top_p=1.0,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.05,\n",
    ")\n",
    "\n",
    "out_rows = []\n",
    "for _, r in tqdm(df.iterrows(), total=len(df)):\n",
    "    row = r.to_dict()\n",
    "    \n",
    "    # PIL 이미지 로드 (있으면)\n",
    "    image = load_image_any(row.get(\"input\")) if row.get(\"input_type\") == \"image\" else None\n",
    "    \n",
    "    # <<< CHANGED: messages엔 자리표시자만 전달\n",
    "    messages = build_messages(row, has_image=image is not None)\n",
    "    \n",
    "    # <<< CHANGED: chat 템플릿을 '토크나이즈된 텐서'로 받음\n",
    "    text_in = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # <<< CHANGED: content 대신 image 변수를 사용\n",
    "    inputs = processor(\n",
    "        text=text_in,\n",
    "        images=[image] if image is not None else None,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generated_ids = model.generate(**inputs, **gen_kwargs)\n",
    "        \n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    # special token 제거 → 어시스턴트 답만\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0].strip()\n",
    "\n",
    "    \n",
    "    out_rows.append({\"id\": r[id_col], \"output\": output_text})\n",
    "    \n",
    "    \n",
    "pd.DataFrame(out_rows).to_csv(out_path, index=False, encoding='utf-8')\n",
    "print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe71341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
