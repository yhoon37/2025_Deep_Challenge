{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1603061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  \"3\"\n",
    "# cuBLAS 결정적 모드 (둘 중 하나 사용) — 반드시 torch import 전에 설정\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"   # 더 큰 워크스페이스\n",
    "\n",
    "# (선택) 기타 재현성 관련\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "import random, numpy as np, torch\n",
    "\n",
    "# 완전 결정적 모드\n",
    "torch.use_deterministic_algorithms(True, warn_only=False)\n",
    "\n",
    "# cuDNN/TF32 설정\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "# 시드 고정\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "import argparse, io, base64, re, requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoProcessor, AutoModelForVision2Seq, BitsAndBytesConfig, AutoTokenizer,\n",
    "    Trainer, TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "SYSTEM_RULES = (\n",
    "    \"You are a multimodal assistant.\\n\"\n",
    "    \"\\n\"\n",
    "    \"GLOBAL FORMAT RULES:\\n\"\n",
    "    \"- Output exactly ONE final block with NO role tags, headers, lists, or extra sections.\\n\"\n",
    "    \"- Never enumerate (no (i)/(ii), numbers, bullets). Do NOT echo instructions.\\n\"\n",
    "    \"- Do NOT wrap output in quotes. No leading/trailing spaces or trailing newline.\\n\"\n",
    "    \"- Preserve original casing, punctuation, and spacing from the source when answering spans.\\n\"\n",
    "    \"\\n\"\n",
    "    \"TASK STYLES (use [TASK_HINT] when present; otherwise infer from inputs):\\n\"\n",
    "    \"1) captioning (image, no explicit question):\\n\"\n",
    "    \"   - Begin the caption with: 'The image is ...'\\n\"\n",
    "    \"   - Write a detailed description in 2–6 sentences (paragraph style), no labels.\\n\"\n",
    "    \"   - No quotes. No list formatting.\\n\"\n",
    "    \"\\n\"\n",
    "    \"2) vqa (image + question):\\n\"\n",
    "    \"   - Return ONLY the exact short answer span as plain text (one line).\\n\"\n",
    "    \"   - Do NOT add words, punctuation, or explanations. Do NOT normalize case or numbers.\\n\"\n",
    "    \"\\n\"\n",
    "    \"3) math_reasoning (word problems):\\n\"\n",
    "    \"   - You MUST output step-by-step reasoning FIRST, then a blank line, then the final line.\\n\"\n",
    "    \"   - Use the numbers from the problem in the steps. Keep units only if required by the answer.\\n\"\n",
    "    \"   - Do NOT output the final line until after the steps are written.\\n\"\n",
    "    \"   - Write ONLY 4–8 SHORT plain sentences, NO bullets/numbers/latex. NO introductions like 'To determine...' and NO variables such as x.\\n\"\n",
    "    \"   - Each sentence MUST include at least one inline computation marker like '<<a+b=c>>', '<<a-b=c>>', '<<a*b=c>>', or '<<a/b=c>>'. Use the given numbers directly.\\n\"\n",
    "    \"   - Keep the style compact as in the dataset examples.\\n\"\n",
    "    \"   - After the sentences, add ONE blank line and then the final line EXACTLY: '#### <final_answer>' (digits only; decimal allowed; no commas/units).\\n\"\n",
    "    \"   - Examples:\\n\"\n",
    "    \"     Dad gave Olaf 10 toy cars, Mom gave 10 + 5 = <<10+5=15>>15. Auntie gave 6, Uncle gave 6 - 1 = <<6-1=5>>5, Grandpa gave 2 * 5 = <<2*5=10>>10. All gifts total 10 + 15 + 6 + 5 + 10 = <<10+15+6+5+10=46>>46. Olaf now has 150 + 46 = <<150+46=196>>196.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 196\\n\"\n",
    "    \"     He has 6 - 2 = <<6-2=4>>4 cats. He has 4 - 1 = <<4-1=3>>3 parrots. He has 4 + 6 = <<4+6=10>>10 snakes. Total pets 2 + 4 + 3 + 10 = <<2+4+3+10=19>>19.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 19\\n\"\n",
    "    \"     She spend $56 because 7 * 8 = <<7*8=56>>56. She has 100 - 56 = <<100-56=44>>44 left. She can get 44 / 5 = <<44/5=8.8>>8.8 five-dollar bills → $40 because 8 * 5 = <<8*5=40>>40. Money left 44 - 40 = <<44-40=4>>4.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 4\\n\"\n",
    "    \"     Mimi picked up 2 dozen seashells, which is <<2*12=24>> shells. Kyle found twice as many, so <<24*2=48>> shells. Leigh grabbed one-third of Kyle's shells, so <<48/3=16>> shells.\\n\"\n",
    "    \"     \\n\"\n",
    "    \"     #### 16\\n\"\n",
    "    \"\\n\"\n",
    "    \"4) summarization (long text, no direct question):\\n\"\n",
    "    \"   - If a formal act title exists (e.g., explicit short title line or '<TITLE> of <YEAR>'), OUTPUT EXACTLY '<TITLE> - <summary>' on ONE line.\\n\"\n",
    "    \"   - The part AFTER ' - ' MUST be a NON-EMPTY summary of 20–60 words (1–3 sentences). Title-only output is INVALID.\\n\"\n",
    "    \"   - If no clear title exists, output a single-line summary of 20–60 words (no line breaks).\\n\"\n",
    "    \"   - NEVER include raw headings like 'SECTION 1. SHORT TITLE.' or 'SEC.' in the output. Do NOT write 'Title - ...'. Start with the actual title text only.\\n\"\n",
    "    \"   - Do NOT mention 'image' or 'document'. Focus on the bill’s purpose, actions (Directs/Requires/Establishes/Authorizes), scope, and any key targets/timelines.\\n\"\n",
    "    \"   - If your draft lacks the ' - ' or has fewer than 20 words after it, treat it as INVALID and rewrite before finishing.\\n\"\n",
    "    \"   - Examples:\\n\"\n",
    "    \"     'Veterans Access to Timely Medical Appointments Act - Directs VA to implement a standardized scheduling policy with 7-day primary care and 14-day specialty targets, require reliable wait-time data, strengthen training and oversight, improve phone access, and publish performance reports.'\\n\"\n",
    "    \"     'King Holiday and Service Act of 1994 - Extends and revises the commission honoring Martin Luther King, Jr., expands service opportunities and grant authority, updates reporting and membership requirements, and aligns provisions in the National and Community Service Act.'\\n\"\n",
    "    \"     'Establishes the Commission To Assess the Nuclear Activities of the Islamic Republic of Iran which shall assess the status of, the relationship between, and the intentions behind the military and the civilian nuclear activities of the Islamic Republic of Iran.\\n\\nTerminates the Commission 60 days after submission of the report required under this Act.'\\n\"\n",
    "    \"\\n\"\n",
    "    \"5) text_qa (multiple questions provided):\\n\"\n",
    "    \"   - Return a Python-style dict string with ONLY one key: 'input_text'.\\n\"\n",
    "    \"   - Its value is a JSON-like list of answers in the SAME order as the questions.\\n\"\n",
    "    \"   - Example: {'input_text': ['ans1', 'ans2', 'ans3']}\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_prompt(row: dict) -> str:\n",
    "    lines = []\n",
    "    if row.get(\"task\"):     lines.append(f\"[TASK_HINT]: {row['task']}\")\n",
    "    if row.get(\"question\"): lines.append(f\"[QUESTION]: {row['question']}\")\n",
    "    if row.get(\"input_type\") == \"text\" and row.get(\"input\"):\n",
    "        lines.append(f\"[TEXT]: {row['input']}\")\n",
    "    lines.append(\"Respond with the single best answer only.\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# <<< CHANGED: messages엔 '자리표시자'만 두고, PIL 이미지는 넣지 않음\n",
    "def build_messages(row, has_image: bool):\n",
    "    user_content = []\n",
    "    if has_image:\n",
    "        user_content.append({\"type\": \"image\"})  # 자리표시자만\n",
    "    user_content.append({\"type\": \"text\", \"text\": build_prompt(row)})\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\":\"text\", \"text\": SYSTEM_RULES}]},\n",
    "        {\"role\": \"user\",   \"content\": user_content},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def build_messages_from_row(row: dict) -> list:\n",
    "    \"\"\"한 샘플의 messages(list[dict])를 생성.\n",
    "       이미지가 여러 장이면 모두 user content에 추가.\"\"\"\n",
    "    user_content = []\n",
    "    \n",
    "    # 이미지 프롬프트\n",
    "    img = load_image_any(row.get(\"input\")) if row.get(\"input_type\") == \"image\" else None\n",
    "    if img is not None:\n",
    "         user_content.append({\"type\": \"image\", \"image\": img})  # 이미지 객체를 그대로 넣음\n",
    "    # 텍스트 프롬프트\n",
    "    user_content.append({\"type\": \"text\", \"text\": build_prompt(row)})\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_RULES},  # 문자열 그대로\n",
    "        {\"role\": \"user\",   \"content\": user_content},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def load_image_any(x: str):\n",
    "    if not isinstance(x, str):\n",
    "        return None\n",
    "    if x.startswith(\"http://\") or x.startswith(\"https://\"):\n",
    "        try:\n",
    "            r = requests.get(x, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            return None\n",
    "    try:\n",
    "        raw = base64.b64decode(x, validate=True)\n",
    "        return Image.open(io.BytesIO(raw)).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def find_id_col(df: pd.DataFrame):\n",
    "    for c in (\"ID\",\"id\"):\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\":\"ID\"}, inplace=True)\n",
    "    return \"ID\"\n",
    "\n",
    "# 학습용 답변 컬럼 추정: 우선순위대로 찾기\n",
    "def get_target_text(row: dict) -> str:\n",
    "    for k in (\"output\", \"answer\", \"label\", \"target\"):\n",
    "        if isinstance(row.get(k), str) and len(row[k].strip()) > 0:\n",
    "            return row[k].strip()\n",
    "    # 없으면 빈 문자열 반환(로스 없음)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0444cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:22<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: Qwen/Qwen2.5-VL-7B-Instruct on cuda:0\n",
      "trainable params: 47,892,480 || all params: 8,340,059,136 || trainable%: 0.5742\n",
      "DATASET LOADED\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration\n",
    "\n",
    "# -----------------------------\n",
    "# 경로/모델/설정\n",
    "# -----------------------------\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  \"3\"\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "DATA_PATH  = \"../data/train.parquet\"   # 학습 데이터\n",
    "VAL_PATH   = \"../data/val.parquet\"   # (옵션) 검증\n",
    "OUTPUT_DIR = \"./qwen2_5_vl_7b_lora_2\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4bit 양자화\n",
    "# -----------------------------\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "device_map = \"auto\"\n",
    "\n",
    "# -----------------------------\n",
    "# Processor & Model\n",
    "# -----------------------------\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "base = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    "    #attn_implementation=\"flash_attention_2\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "print(f\"Loaded model: {MODEL_NAME} on {base.device}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 생성 파라미터(결정적)\n",
    "# -----------------------------\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=352,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.05,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# QLoRA 준비\n",
    "# -----------------------------\n",
    "# 1) QLoRA 준비\n",
    "base = prepare_model_for_kbit_training(base)\n",
    "base.config.use_cache = False\n",
    "base.enable_input_require_grads()\n",
    "base.gradient_checkpointing_enable()\n",
    "\n",
    "# 2) LoRA 타겟: LLM + projector(★핵심)\n",
    "target_modules = [\n",
    "    # LLM\n",
    "    \"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
    "    \"gate_proj\",\"up_proj\",\"down_proj\",\n",
    "    # Projector (visual.merger.mlp: 5120->3584)\n",
    "    \"merger.mlp.0\",\"merger.mlp.2\",\n",
    "]\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "    target_modules=target_modules,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(base, lora_cfg)\n",
    "model.to(\"cuda\")\n",
    "model.print_trainable_parameters()\n",
    "# -----------------------------\n",
    "# 데이터셋\n",
    "# -----------------------------\n",
    "class VLParquetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, parquet_path: str):\n",
    "        self.df = pd.read_parquet(parquet_path, engine=\"pyarrow\")\n",
    "        self.id_col = find_id_col(self.df)\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx].to_dict()\n",
    "        has_img = (row.get(\"input_type\") == \"image\") and isinstance(row.get(\"input\"), str)\n",
    "        messages = build_messages_from_row(row)\n",
    "\n",
    "        # 학습용 텍스트: prompt(+assistant 헤더) + 정답 + <|im_end|>\n",
    "        prompt_text = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        target = get_target_text(row)\n",
    "        # target이 비어도 괜찮지만, 실제 SFT는 비어있지 않은 데이터가 좋아요.\n",
    "        full_text = f\"{prompt_text}{target}<|im_end|>\"\n",
    "\n",
    "        image = load_image_any(row.get(\"input\")) if has_img else None\n",
    "        return {\n",
    "            \"messages\": messages,           # 프롬프트 재생성용\n",
    "            \"prompt_text\": prompt_text,     # prefix 길이 계산용\n",
    "            \"full_text\": full_text,         # 실제 입력\n",
    "            \"image\": image,\n",
    "            \"id\": row[self.id_col],\n",
    "        }\n",
    "\n",
    "train_ds = VLParquetDataset(DATA_PATH)\n",
    "eval_ds  = VLParquetDataset(VAL_PATH) if os.path.exists(VAL_PATH) else None\n",
    "print(\"DATASET LOADED\")\n",
    "\n",
    "# -----------------------------\n",
    "# Collator: 배치 인코딩 + 라벨 마스킹\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class VLSFTCollator:\n",
    "    processor: Any\n",
    "    max_length: int = None  # 필요시 최대 토큰수 제한\n",
    "\n",
    "    def __call__(self, features: List[Dict[str,Any]]) -> Dict[str, torch.Tensor]:\n",
    "        # 1) 메시지 리스트로부터 비전 입력 정리 (자리표시자 대응)\n",
    "        messages_list = [f[\"messages\"] for f in features]\n",
    "        image_inputs, _ = process_vision_info(messages_list)\n",
    "\n",
    "        # 2) 텍스트들 준비\n",
    "        texts_full   = [f[\"full_text\"] for f in features]\n",
    "        texts_prompt = [f[\"prompt_text\"] for f in features]\n",
    "\n",
    "        # 3) 실제 학습 입력(Full) 배치 인코딩\n",
    "        inputs_full = self.processor(\n",
    "            text=texts_full,\n",
    "            images=image_inputs,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # 4) prefix 길이 계산: 프롬프트만 같은 길이로 패딩해서 attention_mask로 길이를 구함\n",
    "        inputs_pref = self.processor(\n",
    "            text=texts_prompt,\n",
    "            images=image_inputs,\n",
    "            padding=\"max_length\",\n",
    "            max_length=inputs_full[\"input_ids\"].shape[1],\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # 5) 라벨 생성: 프롬프트 위치(= inputs_pref.attention_mask==1)는 -100\n",
    "        labels = inputs_full[\"input_ids\"].clone()\n",
    "        labels[inputs_pref[\"attention_mask\"].bool()] = -100\n",
    "\n",
    "        batch = dict(inputs_full)\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "collator = VLSFTCollator(processor, max_length=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0525b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10610' max='10610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10610/10610 69:27:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.728700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.269200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.274400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.965500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.871500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.821300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.681900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>3.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.589800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>3.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.741600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.505800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.813100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.840400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.561900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.608600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.608800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.390500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.703600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.703700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.386100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.649800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.651600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.404900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>3.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>3.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>3.427300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>3.401800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>3.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>3.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>3.474600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>3.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>3.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>3.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>3.450300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>3.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>3.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>3.463800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>3.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>3.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>3.643100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>3.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>3.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>3.463500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>3.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>3.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>3.363500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>3.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>3.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>3.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.388400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>3.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>3.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>3.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>3.377700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>3.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>3.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>3.287800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>3.417100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>3.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.510700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>4.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>4.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>4.207100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>4.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>3.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>3.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>2.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>2.884600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>2.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>2.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>2.822900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>2.916800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>3.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.852200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>2.903500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>2.822400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>2.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>2.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>2.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>2.791800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>2.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>2.808900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>2.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>2.722700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>2.755700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>3.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.945100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>2.868300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>2.707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>2.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>2.839800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>2.806200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>2.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>2.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>2.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>2.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>2.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>2.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>2.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>2.973800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>2.787800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>2.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>2.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>2.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7450</td>\n",
       "      <td>2.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7550</td>\n",
       "      <td>2.836100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>2.921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>2.965300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>2.777200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>2.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>2.644800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7850</td>\n",
       "      <td>2.874400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>2.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7950</td>\n",
       "      <td>2.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.765700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8050</td>\n",
       "      <td>2.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>2.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8150</td>\n",
       "      <td>2.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>2.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>2.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>2.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>3.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>3.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8450</td>\n",
       "      <td>3.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.477700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8550</td>\n",
       "      <td>3.889100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>3.435900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8650</td>\n",
       "      <td>3.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>3.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>3.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>3.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8850</td>\n",
       "      <td>3.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>3.758300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8950</td>\n",
       "      <td>3.598200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9050</td>\n",
       "      <td>3.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>3.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9150</td>\n",
       "      <td>3.519000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>3.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>3.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>3.517900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9350</td>\n",
       "      <td>3.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>3.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>3.556900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9550</td>\n",
       "      <td>3.584900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>3.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9650</td>\n",
       "      <td>3.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>3.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>3.713300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>3.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9850</td>\n",
       "      <td>3.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>3.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9950</td>\n",
       "      <td>3.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.716500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10050</td>\n",
       "      <td>3.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>3.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10150</td>\n",
       "      <td>3.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>3.754100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>3.992600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>3.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10350</td>\n",
       "      <td>3.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>3.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10450</td>\n",
       "      <td>3.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>3.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>3.734000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/qwen25/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 학습 설정\n",
    "# -----------------------------\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,          # VRAM에 맞춰 조절\n",
    "    gradient_accumulation_steps=8,\n",
    "    per_device_eval_batch_size=1,\n",
    "    learning_rate=1e-4,                     # LoRA는 1e-4 ~ 2e-4 자주 사용\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    #evaluation_strategy=\"steps\" if eval_ds is not None else \"no\",\n",
    "    save_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\",               # bitsandbytes 최적화기\n",
    "    ddp_find_unused_parameters=False,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "# 캐시 비활성화(gradient checkpointing과 충돌 방지)\n",
    "model.config.use_cache = False\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# LoRA 어댑터 저장\n",
    "trainer.model.save_pretrained(os.path.join(OUTPUT_DIR, \"lora_adapter\"))\n",
    "processor.save_pretrained(OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
